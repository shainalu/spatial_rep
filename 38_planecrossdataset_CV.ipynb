{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndynamic alpha for plane cross dataset for brain areas over a cutoff in both ST and ABA\\n\\nShaina Lu\\nZador & Gillis Labs\\nMarch 2021\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "dynamic alpha for plane cross dataset for brain areas over a cutoff in both ST and ABA\n",
    "\n",
    "Shaina Lu\n",
    "Zador & Gillis Labs\n",
    "March 2021\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file paths\n",
    "ALLEN_FILT_PATH = \"/home/slu/spatial/data/ABAISH_filt_v6.h5\" #non-averaged version\n",
    "ONTOLOGY_PATH = \"/data/slu/allen_adult_mouse_ISH/ontologyABA.csv\"\n",
    "ST_CANTIN_FILT_PATH = \"/home/slu/spatial/data/cantin_ST_filt_v2.h5\"\n",
    "ALLEN_PLANES_PATH = '/home/slu/spatial/data/ABAplanes_v2.h5'\n",
    "\n",
    "#outfiles\n",
    "MOD_TEST_OUT = \"crossplane_SAGtest_CV_032621.csv\"\n",
    "MOD_TRAIN_OUT = \"crossplane_SAGtrain_CV_032621.csv\"\n",
    "CROSS1_ALL_OUT = \"crossplane_SAGtoST_CV_032621.csv\"\n",
    "CROSS2_ALL_OUT = \"crossplane_SAGtoCOR_CV_032621.csv\"\n",
    "\n",
    "OUT_PATH_2 = \"crossplane_bestparams_032621.csv\"\n",
    "OUT_PATH_3 = \"crossplane_meantestscore_032621\"\n",
    "OUT_PATH_4 = \"crossplane_meanteststd_032621\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#read in data and pre-processing functions\n",
    "def read_ABAdata():\n",
    "    \"\"\"read in all ABA datasets needed using pandas\"\"\"\n",
    "    metabrain = pd.read_hdf(ALLEN_FILT_PATH, key='metabrain', mode='r')\n",
    "    voxbrain = pd.read_hdf(ALLEN_FILT_PATH, key='voxbrain', mode='r')\n",
    "    propontvox = pd.read_hdf(ALLEN_FILT_PATH, key='propontology', mode='r')\n",
    "    geneIDName = pd.read_hdf(ALLEN_FILT_PATH, key='geneIDName', mode='r')\t\n",
    "\n",
    "    return metabrain, voxbrain, propontvox, geneIDName\n",
    "\n",
    "def read_STdata():\n",
    "    \"\"\"read in all ST datasets needed using pandas\"\"\"\n",
    "    STspotsmeta = pd.read_hdf(ST_CANTIN_FILT_PATH, key='STspotsmeta', mode='r')\n",
    "    STspots = pd.read_hdf(ST_CANTIN_FILT_PATH, key='STspots', mode='r')\n",
    "    STpropont = pd.read_hdf(ST_CANTIN_FILT_PATH, key='STpropont', mode='r')\n",
    "    \n",
    "    return STspotsmeta, STspots, STpropont\n",
    "\n",
    "def read_ontology():\n",
    "    ontology = pd.read_csv(ONTOLOGY_PATH)\n",
    "    ontology = ontology.drop([ontology.columns[5], ontology.columns[6]], axis=1)\n",
    "    ontology = ontology.fillna(-1)  #make root's parent -1\n",
    "\n",
    "    return ontology\n",
    "\n",
    "def read_ABAplanes():\n",
    "    sagvoxbrain = pd.read_hdf(ALLEN_PLANES_PATH, key='sagvoxbrain', mode='r')\n",
    "    corvoxbrain = pd.read_hdf(ALLEN_PLANES_PATH, key='corvoxbrain', mode='r')\n",
    "    \n",
    "    return sagvoxbrain, corvoxbrain\n",
    "\n",
    "def filterproponto(sampleonto, cutoff):\n",
    "    \"\"\"pre-processing for propogated ontology, cutoff param added for CV\"\"\"\n",
    "    #remove brain areas that don't have any samples\n",
    "    sampleonto_sums = sampleonto.apply(lambda col: col.sum(), axis=0)\n",
    "    sampleonto = sampleonto.loc[:,sampleonto_sums > cutoff] \n",
    "    \n",
    "    return sampleonto\n",
    "\n",
    "def getleaves(propontvox, ontology):\n",
    "    \"\"\"helper function to get only leaf brain areas\"\"\"\n",
    "    #leaves are brain areas in the ontology that never show up in the parent column\n",
    "    allareas = list(propontvox)\n",
    "    parents = list(ontology.parent)\n",
    "    for i in range(len(parents)): #convert parents from float to int, ids are ints\n",
    "        parents[i] = int(parents[i])\n",
    "    \n",
    "    #remove parents from all areas\n",
    "    leaves = []\n",
    "    for area in allareas:\n",
    "        if int(area) not in parents:\n",
    "            leaves.append(area)\n",
    "    \n",
    "    print(\"number of leaf areas: %d\" %len(leaves))\n",
    "    return leaves\n",
    "\n",
    "def findoverlapareas(STonto, propontvox, ontology):\n",
    "    \"\"\"find leaf brain areas overlapping between the two datasets\"\"\"\n",
    "    leafST = getleaves(STonto, ontology)\n",
    "    leafABA = getleaves(propontvox, ontology)\n",
    "\n",
    "    leafboth = [] \n",
    "    for i in range(len(leafABA)):\n",
    "        if leafABA[i] in leafST:\n",
    "            leafboth.append(leafABA[i])\n",
    "    \n",
    "    STonto = STonto.loc[:,leafboth]\n",
    "    propontvox = propontvox.loc[:,leafboth]\n",
    "    \n",
    "    return STonto, propontvox    \n",
    "\n",
    "def getoverlapgenes(corvoxbrain,sagvoxbrain,STspots):\n",
    "    \"\"\"find genes that are present in all 3 datasets using gene symbol directly\"\"\"\n",
    "    #this function is new from before, but same idea as sptial/10_crossdataset.py\n",
    "    corgenes = list(corvoxbrain)\n",
    "    saggenes = list(sagvoxbrain)\n",
    "    STgenes = list(STspots)\n",
    "\n",
    "    #getoverlapping genes\n",
    "    overlap = []\n",
    "    for i in range(len(STgenes)):\n",
    "        if STgenes[i] in corgenes:\n",
    "            if STgenes[i] in saggenes:\n",
    "                overlap.append(STgenes[i])\n",
    "\n",
    "    print(\"number of overlapping genes: %d\" %len(overlap))\n",
    "\n",
    "    #subset datasets to only keep genes that are overlapping\n",
    "    corvoxbrain = corvoxbrain.loc[:,overlap]\n",
    "    sagvoxbrain = sagvoxbrain.loc[:,overlap]\n",
    "    STspots = STspots.loc[:,overlap]\n",
    "\n",
    "    return corvoxbrain, sagvoxbrain, STspots\n",
    "\n",
    "def zscore(voxbrain):\n",
    "    \"\"\"zscore voxbrain or subsets of voxbrain (rows: voxels, cols: genes)\"\"\"\n",
    "    #z-score on whole data set before splitting into test and train\n",
    "    scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "    scaler.fit(voxbrain)\n",
    "    z_voxbrain = scaler.transform(voxbrain)\n",
    "    \n",
    "    #store z-scored voxbrain as pandas dataframe\n",
    "    z_voxbrain = pd.DataFrame(z_voxbrain)\n",
    "    z_voxbrain.columns = voxbrain.columns\n",
    "    z_voxbrain.index = voxbrain.index\n",
    "    \n",
    "    return z_voxbrain\n",
    "\n",
    "def analytical_auroc(featurevector, binarylabels):\n",
    "    \"\"\"analytical calculation of auroc\n",
    "       inputs: feature (mean rank of expression level), binary label (ctxnotctx)\n",
    "       returns: auroc\n",
    "    \"\"\"\n",
    "    #sort ctxnotctx binary labels by mean rank, aescending\n",
    "    s = sorted(zip(featurevector, binarylabels))\n",
    "    feature_sort, binarylabels_sort = map(list, zip(*s))\n",
    "\n",
    "    #get the sum of the ranks in feature vector corresponding to 1's in binary vector\n",
    "    sumranks = 0\n",
    "    for i in range(len(binarylabels_sort)):\n",
    "        if binarylabels_sort[i] == 1:\n",
    "            sumranks = sumranks + feature_sort[i]\n",
    "    \n",
    "    poslabels = binarylabels.sum()\n",
    "    neglabels = (len(binarylabels) - poslabels)\n",
    "    \n",
    "    auroc = ((sumranks/(neglabels*poslabels)) - ((poslabels+1)/(2*neglabels)))\n",
    "    \n",
    "    return auroc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "ontology = read_ontology()\n",
    "ABAmeta, ABAvox, ABApropont, geneIDName = read_ABAdata()\n",
    "STmeta, STspots, STpropont = read_STdata()\n",
    "sagvoxbrain, corvoxbrain = read_ABAplanes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of leaf areas: 65\n",
      "number of leaf areas: 139\n",
      "number of overlapping genes: 3737\n"
     ]
    }
   ],
   "source": [
    "#filter brain areas for those that have at least x samples\n",
    "STpropont = filterproponto(STpropont, 100)\n",
    "ABApropont = filterproponto(ABApropont, 100)\n",
    "#filter brain areas for overlapping leaf areas\n",
    "STpropont, ABApropont = findoverlapareas(STpropont, ABApropont, ontology)\n",
    "\n",
    "#keep only genes that are overlapping between the datasets\n",
    "corvoxbrain, sagvoxbrain, STspots = getoverlapgenes(corvoxbrain, sagvoxbrain, STspots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows that don't have any samples\n",
    "STrowsum = STpropont.sum(axis=1)\n",
    "STpropont = STpropont.loc[STrowsum > 0, :]\n",
    "STspots = STspots.loc[STrowsum > 0, :]\n",
    "\n",
    "ABArowsum = ABApropont.sum(axis=1)\n",
    "ABApropont = ABApropont.loc[ABArowsum > 0, :]\n",
    "corvoxbrain = corvoxbrain.loc[ABArowsum > 0, :]\n",
    "sagvoxbrain = sagvoxbrain.loc[ABArowsum > 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlapping areas with X samples: 62\n"
     ]
    }
   ],
   "source": [
    "print(\"overlapping areas with X samples: %d\" %ABApropont.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval(X, y):\n",
    "    \"\"\"helper function to perform actual cross validation on train fold\"\"\"\n",
    "    ssplits = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n",
    "    model = Lasso(max_iter=10000)\n",
    "    alpha = [0.01, 0.05, 0.1, 0.2, 0.5, 0.9]\n",
    "\n",
    "    grid = dict(alpha=alpha)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, \\\n",
    "                               cv=ssplits, scoring='roc_auc', error_score=-1)\n",
    "    \n",
    "    grid_result = grid_search.fit(X,y)\n",
    "    \n",
    "    return grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getallbyall(mod_data, mod_propont, cross1_data, cross1_propont, cross2_data, cross2_propont):\n",
    "    #initialize zeros dataframe to store entries\n",
    "    allbyall_selftest = pd.DataFrame(index=list(mod_propont), columns=list(mod_propont))\n",
    "    allbyall_selftrain = pd.DataFrame(index=list(mod_propont), columns=list(mod_propont))\n",
    "    allbyall_cross1 = pd.DataFrame(index=list(mod_propont), columns=list(mod_propont))\n",
    "    allbyall_cross2 = pd.DataFrame(index=list(mod_propont), columns=list(mod_propont))\n",
    "\n",
    "    bestparams = pd.DataFrame(index=list(mod_propont), columns=list(mod_propont))\n",
    "    bestparams = bestparams.fillna(0)\n",
    "    meantestscore = {}\n",
    "    meanteststd = {}\n",
    "\n",
    "\n",
    "    areas = list(mod_propont)\n",
    "    #for each column, brain area\n",
    "    for i in range(mod_propont.shape[1]):\n",
    "    #for i in range(5,6,1):\n",
    "        print(\"col %d\" %i)\n",
    "        #for each row in each column\n",
    "        for j in range(i+1,mod_propont.shape[1]): #upper triangular!\n",
    "            area1 = areas[i]\n",
    "            area2 = areas[j]\n",
    "            #get binary label vectors\n",
    "            ylabels = mod_propont.loc[mod_propont[area1]+mod_propont[area2] != 0, area1]\n",
    "            ycross1 = cross1_propont.loc[cross1_propont[area1]+cross1_propont[area2] != 0, area1]\n",
    "            ycross2 = cross2_propont.loc[cross2_propont[area1]+cross2_propont[area2] !=0, area1]\n",
    "            #ylabels = pd.Series(np.random.permutation(ylabels1),index=ylabels1.index) #try permuting\n",
    "\n",
    "            #subset train and test sets for only samples in the two areas\n",
    "            Xcurr = mod_data.loc[mod_propont[area1]+mod_propont[area2] != 0, :]\n",
    "            Xcross1curr = cross1_data.loc[cross1_propont[area1]+cross1_propont[area2] != 0, :]\n",
    "            Xcross2curr = cross2_data.loc[cross2_propont[area1]+cross2_propont[area2] != 0, :]\n",
    "            #split train test for X data and y labels\n",
    "            #split data function is seeded so all will split the same way\n",
    "            Xtrain, Xtest, ytrain, ytest = train_test_split(Xcurr, ylabels, test_size=0.5,\\\n",
    "                                                            random_state=42, shuffle=True,\\\n",
    "                                                            stratify=ylabels)\n",
    "            #z-score train and test folds\n",
    "            zXtrain = zscore(Xtrain)\n",
    "            zXtest = zscore(Xtest)\n",
    "            zXcross1 = zscore(Xcross1curr)\n",
    "            zXcross2 = zscore(Xcross2curr)\n",
    "\n",
    "            #further stratified splits for CV\n",
    "            #bestscore, bestparams, meantestscore, meanteststd = \n",
    "            gridresult = crossval(zXtrain, ytrain)\n",
    "\n",
    "            #use best estimator from CV for mod test and cross test\n",
    "            #test\n",
    "            predictions_test = gridresult.best_estimator_.predict(zXtest)\n",
    "            auroc_test = analytical_auroc(sp.stats.mstats.rankdata(predictions_test), ytest)\n",
    "            #cross1\n",
    "            predictions_cross1 = gridresult.best_estimator_.predict(zXcross1)\n",
    "            auroc_cross1 = analytical_auroc(sp.stats.mstats.rankdata(predictions_cross1), ycross1)\n",
    "            #cross2\n",
    "            predictions_cross2 = gridresult.best_estimator_.predict(zXcross2)\n",
    "            auroc_cross2 = analytical_auroc(sp.stats.mstats.rankdata(predictions_cross2), ycross2)\n",
    "\n",
    "            allbyall_selftrain.iloc[i,j] = gridresult.best_score_\n",
    "            allbyall_selftest.iloc[i,j] = auroc_test\n",
    "            allbyall_cross1.iloc[i,j] = auroc_cross1\n",
    "            allbyall_cross2.iloc[i,j] = auroc_cross2\n",
    "\n",
    "            bestparams.iloc[i,j] = gridresult.best_params_['alpha']\n",
    "            key = \"%s,%s\" %(str(i), str(j))\n",
    "            meantestscore[key] = gridresult.cv_results_['mean_test_score']\n",
    "            meanteststd[key] = gridresult.cv_results_['std_test_score']\n",
    "            #break\n",
    "\n",
    "        #if i == 1:\n",
    "        #break\n",
    "\n",
    "    #return temp\n",
    "    return allbyall_selftrain, allbyall_selftest, allbyall_cross1, allbyall_cross2, bestparams, meantestscore, meanteststd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-61205011fb36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mallbyall_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallbyall_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallbyall_cross1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallbyall_cross2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeantestscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanteststd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetallbyall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msagvoxbrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABApropont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTspots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTpropont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorvoxbrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABApropont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-96-b6c66f6511f1>\u001b[0m in \u001b[0;36mgetallbyall\u001b[0;34m(mod_data, mod_propont, cross1_data, cross1_propont, cross2_data, cross2_propont)\u001b[0m\n\u001b[1;32m     37\u001b[0m                                                             stratify=ylabels)\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m#z-score train and test folds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mzXtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mzXtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mzXcross1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXcross1curr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-1bcf03a57c40>\u001b[0m in \u001b[0;36mzscore\u001b[0;34m(voxbrain)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m#z-score on whole data set before splitting into test and train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoxbrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0mz_voxbrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoxbrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/batch/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/batch/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    726\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples_seen_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m                     _incremental_mean_and_var(X, self.mean_, self.var_,\n\u001b[0;32m--> 728\u001b[0;31m                                               self.n_samples_seen_)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;31m# for backward-compatibility, reduce n_samples_seen_ to an integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/batch/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36m_incremental_mean_and_var\u001b[0;34m(X, last_mean, last_variance, last_sample_count)\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0;31m# updated = the aggregated stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[0mlast_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_mean\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlast_sample_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m     \u001b[0mnew_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_accumulator_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnansum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0mnew_sample_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/batch/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36m_safe_accumulator_op\u001b[0;34m(op, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/batch/lib/python3.7/site-packages/numpy/lib/nanfunctions.py\u001b[0m in \u001b[0;36mnansum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \"\"\"\n\u001b[1;32m    613\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_replace_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/batch/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   2074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2076\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/batch/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "allbyall_train, allbyall_test, allbyall_cross1, allbyall_cross2, bestparams, meantestscore, meanteststd = getallbyall(sagvoxbrain, ABApropont, STspots, STpropont, corvoxbrain, ABApropont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0,1': array([0.02041409, 0.01702898, 0.02060804, 0.1117316 , 0.        ,\n",
       "        0.        ])}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanteststd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
