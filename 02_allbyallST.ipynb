{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntest reading output file from 1_datafilter.ipynb\\nset-up to run allbyall for new ST\\n\\nShaina Lu\\nZador & Gillis Lab\\nApril 2020\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "test reading output file from 1_datafilter.ipynb\n",
    "set-up to run allbyall for new ST\n",
    "\n",
    "Shaina Lu\n",
    "Zador & Gillis Lab\n",
    "April 2020\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split #stratify train/test split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_style():\n",
    "    #function for matplotlib formatting\n",
    "    plt.style.use(['seaborn-white','seaborn-notebook'])\n",
    "    plt.rcParams['figure.figsize'] = [6,4]\n",
    "    plt.rcParams['axes.spines.top'] = False       #remove top line\n",
    "    plt.rcParams['axes.spines.right'] = False     #remove right line\n",
    "    plt.rcParams['axes.linewidth'] = 2.0          #set weight of axes\n",
    "    plt.rcParams['axes.titlesize'] = 20           #set font size of title\n",
    "    plt.rcParams['axes.labelsize'] = 18           #set font size of x,y labels\n",
    "    plt.rcParams['axes.labelpad'] = 14            #space between labels and axes\n",
    "    plt.rcParams['xtick.labelsize'] = 14          #set x label size\n",
    "    plt.rcParams['ytick.labelsize'] = 14          #set y label size\n",
    "    plt.rcParams['legend.fontsize'] = 16          #set legend font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#infiles\n",
    "ST_CANTIN_FILT_PATH = \"/home/slu/spatial/data/cantin_ST_filt_v1.h5\"\n",
    "ONTOLOGY_PATH = \"/data/slu/allen_adult_mouse_ISH/ontologyABA.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \"\"\"read in all datasets needed using pandas\"\"\"\n",
    "    STspotsmeta = pd.read_hdf(ST_CANTIN_FILT_PATH, key='STspotsmeta', mode='r')\n",
    "    STspots = pd.read_hdf(ST_CANTIN_FILT_PATH, key='STspots', mode='r')\n",
    "    STpropont = pd.read_hdf(ST_CANTIN_FILT_PATH, key='STpropont', mode='r')\n",
    "\n",
    "    ontology = pd.read_csv(ONTOLOGY_PATH)\n",
    "    ontology = ontology.drop([ontology.columns[5], ontology.columns[6]], axis=1)\n",
    "    ontology = ontology.fillna(-1)  #make root's parent -1\n",
    "\n",
    "    return STspotsmeta, STspots, STpropont, ontology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data read in from filtered ST_cantin h5 file looks good based on head and shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__copied and pasted pre-processing functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def zscore(voxbrain):\n",
    "    \"\"\"zscore voxbrain or subsets of voxbrain (rows: voxels, cols: genes)\"\"\"\n",
    "    #z-score \n",
    "    scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "    scaler.fit(voxbrain)\n",
    "    z_voxbrain = scaler.transform(voxbrain, copy=True)\n",
    "    \n",
    "    #store z-scored voxbrain as pandas dataframe\n",
    "    z_voxbrain = pd.DataFrame(z_voxbrain)\n",
    "    z_voxbrain.columns = voxbrain.columns\n",
    "    z_voxbrain.index = voxbrain.index\n",
    "    \n",
    "    return z_voxbrain\n",
    "\n",
    "def splitdata(data, testratio):\n",
    "    \"\"\"generic fcn to split data in train/test folds\"\"\"\n",
    "    #set seed so train and test will always split the same in diff run so ML algorithm doesn't see whole dataset (BAD)\n",
    "    np.random.seed(42)\n",
    "    shuffindices = np.random.permutation(len(data))\n",
    "    testsize = int(len(data) * testratio)\n",
    "    testindices = shuffindices[:testsize]\n",
    "    trainindices = shuffindices[testsize:]\n",
    "    return data.iloc[trainindices], data.iloc[testindices]\n",
    "\n",
    "def filterproponto(sampleonto):\n",
    "    \"\"\"pre-processing for propogated ontology for ST data\"\"\"\n",
    "    #remove brain areas that don't have any samples\n",
    "    sampleonto_sums = sampleonto.apply(lambda col: col.sum(), axis=0)\n",
    "    sampleonto = sampleonto.loc[:,sampleonto_sums > 5] #greater than 5 becuase less is not enough for train/test split to have non-zero areas\n",
    "    \n",
    "    return sampleonto\n",
    "\n",
    "def getleaves(propontvox, ontology):\n",
    "    #leaves are brain areas in the ontology that never show up in the parent column\n",
    "    allareas = list(propontvox)\n",
    "    parents = list(ontology.parent)\n",
    "    for i in range(len(parents)): #convert parents from float to int, ids are ints\n",
    "        parents[i] = int(parents[i])\n",
    "    \n",
    "    #remove parents from all areas\n",
    "    leaves = []\n",
    "    for area in allareas:\n",
    "        if int(area) not in parents:\n",
    "            leaves.append(area)\n",
    "    \n",
    "    return leaves\n",
    "\n",
    "def analytical_auroc(featurevector, binarylabels):\n",
    "    \"\"\"analytical calculation of auroc\n",
    "       inputs: feature (mean rank of expression level), binary label\n",
    "       returns: auroc\n",
    "    \"\"\"\n",
    "    #sort ctxnotctx binary labels by mean rank, aescending\n",
    "    s = sorted(zip(featurevector, binarylabels))\n",
    "    feature_sort, binarylabels_sort = map(list, zip(*s))\n",
    "    #print feature_sort\n",
    "    #print binarylabels_sort\n",
    "\n",
    "    #get the sum of the ranks in feature vector corresponding to 1's in binary vector\n",
    "    sumranks = 0\n",
    "    for i in range(len(binarylabels_sort)):\n",
    "        if binarylabels_sort[i] == 1:\n",
    "            sumranks = sumranks + feature_sort[i]\n",
    "    \n",
    "    poslabels = binarylabels.sum()\n",
    "    neglabels = (len(binarylabels) - poslabels) #- (len(binarylabels) - binarylabels.count())  #trying to subtract out \n",
    "    \n",
    "    auroc = ((sumranks/(neglabels*poslabels)) - ((poslabels+1)/(2*neglabels)))\n",
    "    \n",
    "    return auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyLASSO(Xtrain, Xtest, ytrain, ytest):\n",
    "    \"\"\"apply LASSO regression\"\"\"\n",
    "    lasso_reg = Lasso(alpha=0.05, max_iter=10000)\n",
    "    #lasso_reg = LinearRegression()\n",
    "    lasso_reg.fit(Xtrain, ytrain)\n",
    "    \n",
    "    #train\n",
    "    predictions_train = lasso_reg.predict(Xtrain)\n",
    "    auroc_train = analytical_auroc(sp.stats.mstats.rankdata(predictions_train), ytrain)\n",
    "    #test\n",
    "    predictions_test = lasso_reg.predict(Xtest)\n",
    "    auroc_test = analytical_auroc(sp.stats.mstats.rankdata(predictions_test), ytest)\n",
    "    \n",
    "    return auroc_train, auroc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getallbyall(data, propont):\n",
    "    #initialize zeros dataframe to store entries\n",
    "    allbyall_test = pd.DataFrame(index=list(propont), columns=list(propont))\n",
    "    allbyall_test = allbyall_test.fillna(0)\n",
    "    allbyall_train = pd.DataFrame(index=list(propont), columns=list(propont))\n",
    "    allbyall_train = allbyall_train.fillna(0)\n",
    "    \n",
    "    areas = list(propont)\n",
    "    #for each column, brain area\n",
    "    for i in range(propont.shape[1]):\n",
    "        print(\"col %d\" %i)\n",
    "        #for each row in each column\n",
    "        for j in range(i+1,propont.shape[1]): #upper triangular!\n",
    "            area1 = areas[i]\n",
    "            area2 = areas[j]\n",
    "            #get binary label vectors\n",
    "            ylabels = propont.loc[propont[area1]+propont[area2] != 0, area1]\n",
    "            #subset train and test sets for only samples in the two areas\n",
    "            Xcurr = data.loc[propont[area1]+propont[area2] != 0, :]\n",
    "            #split train test for X data and y labels\n",
    "            #split data function is seeded so all will split the same wa\n",
    "            Xtrain, Xtest, ytrain, ytest = train_test_split(Xcurr, ylabels, test_size=0.5,\\\n",
    "                                                            random_state=42, shuffle=True,\\\n",
    "                                                            stratify=ylabels)\n",
    "            #ytrain, ytest = splitdata(ylabels, 0.5)\n",
    "            #Xtrain, Xtest = splitdata(Xcurr, 0.5)\n",
    "            #z-score current X data\n",
    "            zXtrain = zscore(Xtrain)\n",
    "            zXtest = zscore(Xtest)\n",
    "            \n",
    "            currauroc_train, currauroc_test = applyLASSO(zXtrain, zXtest, ytrain, ytest)\n",
    "            allbyall_train.iloc[i,j] = currauroc_train\n",
    "            allbyall_test.iloc[i,j] = currauroc_test\n",
    "            #curr_row[0,j] = currauroc\n",
    "            \n",
    "        #if i == 1:\n",
    "        break\n",
    "     \n",
    "    #return temp\n",
    "    return allbyall_train, allbyall_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing\n",
    "STspotsmeta, STspots, STpropont, ontology = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "STpropont = filterproponto(STpropont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "STspots = STspots.astype('float64') #convert int to float for z-scoring\n",
    "#get leaf areas\n",
    "leaves = getleaves(STpropont, ontology)\n",
    "leafSTpropont = STpropont.loc[STspotsmeta.id.isin(leaves),leaves] #subset prop onto for leaf areas\n",
    "leafSTspots = STspots.loc[STspotsmeta.id.isin(leaves),:] #subset data for samples from leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col 0\n"
     ]
    }
   ],
   "source": [
    "#predictability matrix using LASSO\n",
    "allbyall_train, allbyall_test = getallbyall(leafSTspots, leafSTpropont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(STspots.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_index</th>\n",
       "      <th>ML</th>\n",
       "      <th>DV</th>\n",
       "      <th>AP</th>\n",
       "      <th>acronym</th>\n",
       "      <th>name</th>\n",
       "      <th>nuclei</th>\n",
       "      <th>radius</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>02A_15.8x13.04</th>\n",
       "      <td>02A</td>\n",
       "      <td>3.156438</td>\n",
       "      <td>-3.545032</td>\n",
       "      <td>2.245</td>\n",
       "      <td>MOp1</td>\n",
       "      <td>Primary motor area, Layer 1</td>\n",
       "      <td>3</td>\n",
       "      <td>72.832245</td>\n",
       "      <td>3479.641</td>\n",
       "      <td>4936.516</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02A_18.75x13.07</th>\n",
       "      <td>02A</td>\n",
       "      <td>3.012475</td>\n",
       "      <td>-2.692800</td>\n",
       "      <td>2.245</td>\n",
       "      <td>MOp1</td>\n",
       "      <td>Primary motor area, Layer 1</td>\n",
       "      <td>1</td>\n",
       "      <td>76.475977</td>\n",
       "      <td>3491.171</td>\n",
       "      <td>4074.165</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02A_16.74x13.07</th>\n",
       "      <td>02A</td>\n",
       "      <td>3.124975</td>\n",
       "      <td>-3.292800</td>\n",
       "      <td>2.245</td>\n",
       "      <td>MOp1</td>\n",
       "      <td>Primary motor area, Layer 1</td>\n",
       "      <td>1</td>\n",
       "      <td>75.797361</td>\n",
       "      <td>3488.927</td>\n",
       "      <td>4661.036</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02A_17.81x13.08</th>\n",
       "      <td>02A</td>\n",
       "      <td>3.064854</td>\n",
       "      <td>-2.974134</td>\n",
       "      <td>2.245</td>\n",
       "      <td>MOp1</td>\n",
       "      <td>Primary motor area, Layer 1</td>\n",
       "      <td>5</td>\n",
       "      <td>73.206277</td>\n",
       "      <td>3493.646</td>\n",
       "      <td>4348.148</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02A_19.96x14.09</th>\n",
       "      <td>02A</td>\n",
       "      <td>2.831225</td>\n",
       "      <td>-2.405300</td>\n",
       "      <td>2.245</td>\n",
       "      <td>MOp1</td>\n",
       "      <td>Primary motor area, Layer 1</td>\n",
       "      <td>2</td>\n",
       "      <td>77.408797</td>\n",
       "      <td>3783.901</td>\n",
       "      <td>3720.984</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                slice_index        ML        DV     AP acronym  \\\n",
       "02A_15.8x13.04          02A  3.156438 -3.545032  2.245    MOp1   \n",
       "02A_18.75x13.07         02A  3.012475 -2.692800  2.245    MOp1   \n",
       "02A_16.74x13.07         02A  3.124975 -3.292800  2.245    MOp1   \n",
       "02A_17.81x13.08         02A  3.064854 -2.974134  2.245    MOp1   \n",
       "02A_19.96x14.09         02A  2.831225 -2.405300  2.245    MOp1   \n",
       "\n",
       "                                        name  nuclei     radius         x  \\\n",
       "02A_15.8x13.04   Primary motor area, Layer 1       3  72.832245  3479.641   \n",
       "02A_18.75x13.07  Primary motor area, Layer 1       1  76.475977  3491.171   \n",
       "02A_16.74x13.07  Primary motor area, Layer 1       1  75.797361  3488.927   \n",
       "02A_17.81x13.08  Primary motor area, Layer 1       5  73.206277  3493.646   \n",
       "02A_19.96x14.09  Primary motor area, Layer 1       2  77.408797  3783.901   \n",
       "\n",
       "                        y   id  \n",
       "02A_15.8x13.04   4936.516  320  \n",
       "02A_18.75x13.07  4074.165  320  \n",
       "02A_16.74x13.07  4661.036  320  \n",
       "02A_17.81x13.08  4348.148  320  \n",
       "02A_19.96x14.09  3720.984  320  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STspotsmeta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
