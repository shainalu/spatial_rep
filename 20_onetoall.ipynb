{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npiloting of re-do of one to all\\nmodified from:\\n\\nShaina Lu\\nGillis & Zador Labs\\nJune 2020\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "piloting of re-do of one to all\n",
    "modified from: allenadultmouseISH/onetoall_twentythree.ipynb, allenadultmouseISH/allbyall_onetoall.py, \n",
    "and spatial/09_crossdataset.ipynb\n",
    "\n",
    "Shaina Lu\n",
    "Gillis & Zador Labs\n",
    "June 2020\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split #stratify train/test split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for matplotlib formatting\n",
    "def set_style():\n",
    "    plt.style.use(['seaborn-white','seaborn-notebook'])\n",
    "    plt.rcParams['figure.figsize'] = [6,4]\n",
    "    plt.rcParams['axes.spines.top'] = False       #remove top line\n",
    "    plt.rcParams['axes.spines.right'] = False     #remove right line\n",
    "    plt.rcParams['axes.linewidth'] = 2.0          #set weight of axes\n",
    "    plt.rcParams['axes.titlesize'] = 20           #set font size of title\n",
    "    plt.rcParams['axes.labelsize'] = 18           #set font size of x,y labels\n",
    "    plt.rcParams['axes.labelpad'] = 14            #space between labels and axes\n",
    "    plt.rcParams['xtick.labelsize'] = 14          #set x label size\n",
    "    plt.rcParams['ytick.labelsize'] = 14          #set y label size\n",
    "    plt.rcParams['legend.fontsize'] = 16          #set legend font size\n",
    "    \n",
    "set_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in files and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file paths\n",
    "ALLEN_FILT_PATH = \"/home/slu/spatial/data/ABAISH_filt_v6_avgdup.h5\"\n",
    "ONTOLOGY_PATH = \"/data/slu/allen_adult_mouse_ISH/ontologyABA.csv\"\n",
    "ST_CANTIN_FILT_PATH = \"/home/slu/spatial/data/cantin_ST_filt_v2.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ABA\n",
    "def read_ABAdata():\n",
    "    \"\"\"read in all ABA datasets needed using pandas\"\"\"\n",
    "    metabrain = pd.read_hdf(ALLEN_FILT_PATH, key='metabrain', mode='r')\n",
    "    voxbrain = pd.read_hdf(ALLEN_FILT_PATH, key='avgvoxbrain', mode='r')\n",
    "    propontvox = pd.read_hdf(ALLEN_FILT_PATH, key='propontology', mode='r')\n",
    "    #geneIDName = pd.read_hdf(ALLEN_FILT_PATH, key='geneIDName', mode='r')\t\n",
    "\n",
    "    return metabrain, voxbrain, propontvox\n",
    "\n",
    "#ST\n",
    "def read_STdata():\n",
    "    \"\"\"read in all ST datasets needed using pandas\"\"\"\n",
    "    STspotsmeta = pd.read_hdf(ST_CANTIN_FILT_PATH, key='STspotsmeta', mode='r')\n",
    "    STspots = pd.read_hdf(ST_CANTIN_FILT_PATH, key='STspots', mode='r')\n",
    "    STpropont = pd.read_hdf(ST_CANTIN_FILT_PATH, key='STpropont', mode='r')\n",
    "    \n",
    "    return STspotsmeta, STspots, STpropont\n",
    "\n",
    "def read_ontology():\n",
    "    ontology = pd.read_csv(ONTOLOGY_PATH)\n",
    "    ontology = ontology.drop([ontology.columns[5], ontology.columns[6]], axis=1)\n",
    "    ontology = ontology.fillna(-1)  #make root's parent -1\n",
    "\n",
    "    return ontology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions copied from spatial 09_crossdataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def filterproponto(sampleonto):\n",
    "    \"\"\"pre-processing for propogated ontology\"\"\"\n",
    "    #remove brain areas that don't have any samples\n",
    "    sampleonto_sums = sampleonto.apply(lambda col: col.sum(), axis=0)\n",
    "    sampleonto = sampleonto.loc[:,sampleonto_sums > 5] #greater than 5 becuase less is not enough for train/test split to have non-zero areas\n",
    "    \n",
    "    return sampleonto\n",
    "\n",
    "def getleaves(propontvox, ontology):\n",
    "    \"\"\"helper function to get only leaf brain areas\"\"\"\n",
    "    #leaves are brain areas in the ontology that never show up in the parent column\n",
    "    allareas = list(propontvox)\n",
    "    parents = list(ontology.parent)\n",
    "    for i in range(len(parents)): #convert parents from float to int, ids are ints\n",
    "        parents[i] = int(parents[i])\n",
    "    \n",
    "    #remove parents from all areas\n",
    "    leaves = []\n",
    "    for area in allareas:\n",
    "        if int(area) not in parents:\n",
    "            leaves.append(area)\n",
    "    \n",
    "    print(\"number of leaf areas: %d\" %len(leaves))\n",
    "    return leaves\n",
    "\n",
    "def findoverlapareas(STonto, propontvox, ontology):\n",
    "    \"\"\"find leaf brain areas overlapping between the two datasets\"\"\"\n",
    "    leafST = getleaves(STonto, ontology)\n",
    "    leafABA = getleaves(propontvox, ontology)\n",
    "\n",
    "    leafboth = [] \n",
    "    for i in range(len(leafABA)):\n",
    "        if leafABA[i] in leafST:\n",
    "            leafboth.append(leafABA[i])\n",
    "    \n",
    "    STonto = STonto.loc[:,leafboth]\n",
    "    propontvox = propontvox.loc[:,leafboth]\n",
    "    \n",
    "    return STonto, propontvox    \n",
    "\n",
    "def zscore(voxbrain):\n",
    "    \"\"\"zscore voxbrain or subsets of voxbrain (rows: voxels, cols: genes)\"\"\"\n",
    "    #z-score on whole data set before splitting into test and train\n",
    "    scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "    scaler.fit(voxbrain)\n",
    "    z_voxbrain = scaler.transform(voxbrain)\n",
    "    \n",
    "    #store z-scored voxbrain as pandas dataframe\n",
    "    z_voxbrain = pd.DataFrame(z_voxbrain)\n",
    "    z_voxbrain.columns = voxbrain.columns\n",
    "    z_voxbrain.index = voxbrain.index\n",
    "    \n",
    "    return z_voxbrain\n",
    "\n",
    "def analytical_auroc(featurevector, binarylabels):\n",
    "    \"\"\"analytical calculation of auroc\n",
    "       inputs: feature (mean rank of expression level), binary label (ctxnotctx)\n",
    "       returns: auroc\n",
    "    \"\"\"\n",
    "    #sort ctxnotctx binary labels by mean rank, aescending\n",
    "    s = sorted(zip(featurevector, binarylabels))\n",
    "    feature_sort, binarylabels_sort = map(list, zip(*s))\n",
    "\n",
    "    #get the sum of the ranks in feature vector corresponding to 1's in binary vector\n",
    "    sumranks = 0\n",
    "    for i in range(len(binarylabels_sort)):\n",
    "        if binarylabels_sort[i] == 1:\n",
    "            sumranks = sumranks + feature_sort[i]\n",
    "    \n",
    "    poslabels = binarylabels.sum()\n",
    "    neglabels = (len(binarylabels) - poslabels)\n",
    "    \n",
    "    auroc = ((sumranks/(neglabels*poslabels)) - ((poslabels+1)/(2*neglabels)))\n",
    "    \n",
    "    return auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overlaping genes function copied from 09_crossdataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getoverlapgenes(STspots, ABAvox):\n",
    "    ABAgenes = list(ABAvox)\n",
    "    STgenes = list(STspots)\n",
    "    \n",
    "    #get overlapping genes\n",
    "    overlap = []\n",
    "    for i in range(len(ABAgenes)):\n",
    "        if ABAgenes[i] in STgenes:\n",
    "            overlap.append(ABAgenes[i])\n",
    "    \n",
    "    print(\"number of overlapping genes: %d\" %len(overlap))\n",
    "    \n",
    "    #index datasets to keep only genes that are overlapping\n",
    "    STspots = STspots.loc[:,overlap]\n",
    "    ABAvox = ABAvox.loc[:,overlap]\n",
    "    \n",
    "    return STspots, ABAvox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyLASSO(Xtrain, Xtest, ytrain, ytest):\n",
    "    \"\"\"apply LASSO regression\"\"\"\n",
    "    lasso_reg = Lasso(alpha=0.01,max_iter=10000) #alpha=alphaval) #,max_iter=10000)\n",
    "    #lasso_reg = Ridge(alpha=1.0,max_iter=10000)\n",
    "    #lasso_reg = LinearRegression()\n",
    "    lasso_reg.fit(Xtrain, ytrain)\n",
    "    \n",
    "    #train\n",
    "    predictions_train = lasso_reg.predict(Xtrain)\n",
    "    auroc_train = analytical_auroc(sp.stats.mstats.rankdata(predictions_train), ytrain)\n",
    "    #auroc_train = metrics.roc_auc_score(y_true = ytrain, y_score = predictions_train)\n",
    "    \n",
    "    #test\n",
    "    predictions_test = lasso_reg.predict(Xtest)\n",
    "    auroc_test = analytical_auroc(sp.stats.mstats.rankdata(predictions_test), ytest)\n",
    "    #auroc_test = metrics.roc_auc_score(y_true = ytest, y_score = predictions_test)\n",
    "\n",
    "    return lasso_reg, auroc_train, predictions_test, auroc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getallbyall(mod_data, mod_propont, cross_data, cross_propont):\n",
    "    #initialize zeros dataframe to store entries\n",
    "    onebyall_train = []\n",
    "    onebyall_test = []\n",
    "    allbyall = pd.DataFrame(index=list(mod_propont), columns=list(mod_propont))\n",
    "    crossall = pd.DataFrame(index=list(mod_propont), columns=list(mod_propont))\n",
    "\n",
    "    \n",
    "    areas = list(mod_propont)\n",
    "    #for each column, brain area\n",
    "    for i in range(mod_propont.shape[1]):\n",
    "        print(\"col %d\" %i)\n",
    "        area1 = areas[i]\n",
    "\n",
    "        #get binary label vectors\n",
    "        ylabels = mod_propont.loc[:, area1]\n",
    "\n",
    "        #split train test for X data and y labels\n",
    "        #split data function is seeded so all will split the same way\n",
    "        Xtrain, Xtest, ytrain, ytest = train_test_split(mod_data, ylabels, test_size=0.5,\\\n",
    "                                                        random_state=42, shuffle=True,\\\n",
    "                                                        stratify=ylabels)\n",
    "        #z-score train and test folds\n",
    "        zXtrain = zscore(Xtrain)\n",
    "        zXtest = zscore(Xtest)\n",
    "\n",
    "        #fit LASSO on train set for 1 v all\n",
    "        lassomod, auroc_train, predictions_test, auroc_test = applyLASSO(zXtrain, zXtest, ytrain, ytest)\n",
    "        onebyall_train.append(auroc_train)\n",
    "        onebyall_test.append(auroc_test)\n",
    "        \n",
    "        #get predictions on all v. all\n",
    "        #convert predictions to pandas series for indexing\n",
    "        predictions_test = pd.Series(predictions_test, index=Xtest.index)\n",
    "        #Jesse's approach\n",
    "        for j in range(i+1, mod_propont.shape[1]):\n",
    "            area2 = areas[j]\n",
    "            #get prop ont only for test fold and the two brain areas\n",
    "            test_propont = mod_propont.loc[ytest.index, :]\n",
    "            ytestcurr = test_propont.loc[test_propont[area1]+test_propont[area2] != 0, area1]\n",
    "            #subset predictions for areas in either brain area\n",
    "            currpreds = predictions_test.loc[test_propont[area1]+test_propont[area2] != 0]\n",
    "            #re-rank and calculate new AUROC\n",
    "            currauroc = analytical_auroc(sp.stats.mstats.rankdata(currpreds), ytestcurr)\n",
    "            allbyall.iloc[i,j] = currauroc\n",
    "                    \n",
    "        #get predictions for all v all in cross dataset\n",
    "        for j in range(i+1, mod_propont.shape[1]):\n",
    "            area2 = areas[j]\n",
    "            #get X and y for current comparison\n",
    "            ycross = cross_propont.loc[cross_propont[area1]+cross_propont[area2] != 0, area1]\n",
    "            Xcrosscurr = cross_data.loc[cross_propont[area1]+cross_propont[area2] != 0, :]\n",
    "            zXcross = zscore(Xcrosscurr)\n",
    "            \n",
    "            #predict on cross data\n",
    "            predictions_cross = lassomod.predict(zXcross)\n",
    "            crossall.iloc[i,j] = analytical_auroc(sp.stats.mstats.rankdata(predictions_cross), ycross)\n",
    "            \n",
    "        if i == 1:\n",
    "            break\n",
    "    \n",
    "    onebyall = pd.DataFrame({'train':onebyall_train, 'test':onebyall_test}, columns=['train','test'])\n",
    "    return onebyall, allbyall, crossall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "ontology = read_ontology()\n",
    "ABAmeta, ABAvox, ABApropont = read_ABAdata()\n",
    "\n",
    "STmeta, STspots, STpropont = read_STdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of leaf areas: 461\n",
      "number of leaf areas: 560\n"
     ]
    }
   ],
   "source": [
    "#filter brain areas for those that have at least x samples\n",
    "STpropont = filterproponto(STpropont)\n",
    "ABApropont = filterproponto(ABApropont)\n",
    "#filter brain areas for overlapping leaf areas\n",
    "STpropont, ABApropont = findoverlapareas(STpropont, ABApropont, ontology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of overlapping genes: 14299\n"
     ]
    }
   ],
   "source": [
    "#keep only genes that are overlapping between the two datasets\n",
    "STspots, ABAvox = getoverlapgenes(STspots, ABAvox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col 0\n",
      "col 1\n"
     ]
    }
   ],
   "source": [
    "#predictability matrix using LASSO\n",
    "onebyall, allbyall, crossall = getallbyall(STspots, STpropont, ABAvox, ABApropont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train  test\n",
       "0    0.5   0.5\n",
       "1    0.5   0.5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onebyall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>577</th>\n",
       "      <th>657</th>\n",
       "      <th>1114</th>\n",
       "      <th>606</th>\n",
       "      <th>472</th>\n",
       "      <th>632</th>\n",
       "      <th>1072</th>\n",
       "      <th>893</th>\n",
       "      <th>543</th>\n",
       "      <th>1088</th>\n",
       "      <th>...</th>\n",
       "      <th>785</th>\n",
       "      <th>241</th>\n",
       "      <th>1104</th>\n",
       "      <th>702</th>\n",
       "      <th>954</th>\n",
       "      <th>325</th>\n",
       "      <th>87</th>\n",
       "      <th>82</th>\n",
       "      <th>684</th>\n",
       "      <th>234</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 445 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      577  657 1114  606  472  632 1072  893  543 1088  ...  785  241 1104  \\\n",
       "577   NaN  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  ...  0.5  0.5  0.5   \n",
       "657   NaN  NaN  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  ...  0.5  0.5  0.5   \n",
       "1114  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "606   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "472   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "\n",
       "      702  954  325   87   82  684  234  \n",
       "577   0.5  0.5  0.5  0.5  0.5  0.5  0.5  \n",
       "657   0.5  0.5  0.5  0.5  0.5  0.5  0.5  \n",
       "1114  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "606   NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "472   NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 445 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allbyall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>577</th>\n",
       "      <th>657</th>\n",
       "      <th>1114</th>\n",
       "      <th>606</th>\n",
       "      <th>472</th>\n",
       "      <th>632</th>\n",
       "      <th>1072</th>\n",
       "      <th>893</th>\n",
       "      <th>543</th>\n",
       "      <th>1088</th>\n",
       "      <th>...</th>\n",
       "      <th>785</th>\n",
       "      <th>241</th>\n",
       "      <th>1104</th>\n",
       "      <th>702</th>\n",
       "      <th>954</th>\n",
       "      <th>325</th>\n",
       "      <th>87</th>\n",
       "      <th>82</th>\n",
       "      <th>684</th>\n",
       "      <th>234</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 445 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      577  657 1114  606  472  632 1072  893  543 1088  ...  785  241 1104  \\\n",
       "577   NaN  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  ...  0.5  0.5  0.5   \n",
       "657   NaN  NaN  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  ...  0.5  0.5  0.5   \n",
       "1114  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "606   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "472   NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN   \n",
       "\n",
       "      702  954  325   87   82  684  234  \n",
       "577   0.5  0.5  0.5  0.5  0.5  0.5  0.5  \n",
       "657   0.5  0.5  0.5  0.5  0.5  0.5  0.5  \n",
       "1114  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "606   NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "472   NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 445 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
